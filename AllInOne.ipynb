{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "933b1d77-c135-48c2-b208-20b2923af38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T19:35:03.044365Z",
     "iopub.status.busy": "2024-07-18T19:35:03.043788Z",
     "iopub.status.idle": "2024-07-18T19:35:43.367000Z",
     "shell.execute_reply": "2024-07-18T19:35:43.366102Z",
     "shell.execute_reply.started": "2024-07-18T19:35:03.044331Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 19:35:05.857405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-18 19:35:05.857460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-18 19:35:05.858588: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-18 19:35:05.864616: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 19:35:06.861614: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'cached_download' (from 'huggingface_hub.file_download') is deprecated and will be removed from version '0.26'. Use `hf_hub_download` instead.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30864dddfa124e3fb20d569ad860df34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440f6443d6ab4c2d8739b803c749de0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a1bd55b2c9491fb9f318f37a7396e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270d7d4bc31244219702989a21eb6716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81310b31e2ae484b86244bc4ea39b842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964161bf80ec4b119dcbab583247f0dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69097df09aeb4697b3f86bc476162cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1530441c779c4eebaf003d61d5c03b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/90.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447237413e30452b9f48745a8d90aebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7f3857628c4783875580a130fb22eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7029e4cce8974b6daed1e4babc8a2655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5950f45dd87d49c59f2624d22fd5a116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c2ee1d6cf514e63bdcc8e08c21fcf81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad8d849581b49e28f6cb980940de224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb3f0688b8b4b7a903dfdeba38014db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02db2178fa3e4036be3236835a9c824a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3c1dc1933d447c902075a0759957a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2084250ce0a8474a8f4945346929d8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dff54a33685460da33ac96a06155d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-4k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7d0360348b4155943a1b57bae4cdac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67d5fd7653c48e7a38b2db53f00e778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251a473db66e4beb96536f192996eff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf75926dfc34bdd941b6dc9bb3fb146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac9afc46ed741b796bf55d620453715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a67c8c2c7de4e4197b832490f9f4db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce7ada9fc7c4bcf907e3fdf7bc2366b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe6717f6e034f84ad45c21330f2565e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816fb8f03fa8420f9856ec8aed67e82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53762dfd454041cea5f60aa38be1bd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9613e5adef400c8d21adfd6187974a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import keyphrase_dataset\n",
    "import llm_class\n",
    "import model_inference\n",
    "import output_parser\n",
    "import phrase_extraction_evaluation\n",
    "\n",
    "from datetime import datetime\n",
    "from constants import PHI_MODEL_NAME, EMBEDDING_MODEL_NAME\n",
    "from model_eval import ModelEval\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "model = llm_class.LanguageModel()\n",
    "keyphrase_set = keyphrase_dataset.KeyphraseDataset()\n",
    "inference = model_inference.ModelInferencing(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4751c640-c08b-4ea9-baa3-48c7c08503a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T15:40:29.747622Z",
     "iopub.status.busy": "2024-07-18T15:40:29.747353Z",
     "iopub.status.idle": "2024-07-18T15:40:31.225032Z",
     "shell.execute_reply": "2024-07-18T15:40:31.224473Z",
     "shell.execute_reply.started": "2024-07-18T15:40:29.747602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "Running on public URL: https://5885a571e59563f0b4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5885a571e59563f0b4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test 1\n",
      "Running test 2\n",
      "Running test 3\n"
     ]
    }
   ],
   "source": [
    "def gradio_func(text_prompt: str, samples: int, experiment_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Gradio function to run multiple samples and evaluate them.\n",
    "    Args:\n",
    "        text_prompt (str): The text prompt for generating key phrases.\n",
    "        samples (int): The number of samples to test.\n",
    "        experiment_name (str): The name of the experiment.\n",
    "    Returns:\n",
    "        str: The average metrics from the evaluation.\n",
    "    \"\"\"\n",
    "    prompts.multiple_keyphrases_prompt = text_prompt\n",
    "    tests = keyphrase_set.get_samples(samples)\n",
    "    results = ModelEval.multiple_samples(inference, tests, save_file=experiment_name, print_counts=True)\n",
    "\n",
    "    return (\n",
    "        f\"Avg cosine: {results['cosine']} | \"\n",
    "        f\"Avg labels matched: {results['matchings']} | \"\n",
    "        f\"Avg redundancy: {results['redundancy']} | \"\n",
    "        f\"Avg groundness: {results['groundness']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create the Gradio interface for prompt testing\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_func,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text Prompt\"),\n",
    "        gr.Slider(minimum=1, maximum=500, step=1, label=\"Number of tests\"),\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your experiment name here...\", label=\"Experiment name\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Prompt Testing Interface\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae97a6de-6100-497a-87f3-a81e7a806775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T18:06:32.305198Z",
     "iopub.status.busy": "2024-07-17T18:06:32.303979Z",
     "iopub.status.idle": "2024-07-17T18:06:35.632980Z",
     "shell.execute_reply": "2024-07-17T18:06:35.632506Z",
     "shell.execute_reply.started": "2024-07-17T18:06:32.305149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E.M.T. Convicted of Sexual Attacks on 5 in Brooklyn An emergency medical technician with the Fire Department was convicted on Wednesday of a series of sexual assaults in Brooklyn, including an attack on an 11-year-old girl inside an elevator. The technician, Angus Pascall, 36, was convicted of first-degree rape, among other charges, for five separate attacks on young women and girls ages 11 to 22 stretching to 2001. Most of the assaults occurred in 2009 and 2010, the year he was arrested, the Kings County district attorney, Charles J. Hynes, said in a statement. Mr. Pascall’s lawyer, Edward Friedman, said his client would appeal the verdict. In each of the attacks, Mr. Pascall was armed, sometimes with a gun or a knife. In one attack on a 19-year-old woman in 2009, he used a machete, the district attorney said. In the assault on the 11-year-old, he used his emergency responder’s key to trap the victim inside an elevator. “Pascall then put a gun to her face and repeatedly sexually assaulted her,” according to the statement. He is scheduled to be sentenced on Feb. 13, and he faces up to life in prison. Mr. Pascall had worked for the Fire Department for five years when he was arrested in 2010.\n",
      "\n",
      "\n",
      "['rape', 'angus pascall', 'brooklyn', 'emergency medicine', 'charles hynes', 'decisions and verdicts', 'nyc', 'child abuse']\n",
      "\n",
      "\n",
      "['E.M.T. Convicted', 'Sexual Attacks', 'Brooklyn', 'First-Degree Rape', 'Young Women', '2009', '2010', 'Armed', 'Machete', 'Elevator']\n",
      "{'cosine': 0.5127790588885546, 'matchings': 0.25, 'redundancy': 0.022222222222222223, 'groundness': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Debug\n",
    "\n",
    "sample=keyphrase_set.train_set[1]\n",
    "\n",
    "#print(model.prompt_text)\n",
    "\n",
    "print(sample['text'])\n",
    "print(\"\\n\")\n",
    "print(sample['label'])\n",
    "print(\"\\n\")\n",
    "print(get_metrics(sample['text'],sample['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76463564-cde9-4896-a481-06e71c66cf7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T17:32:26.350827Z",
     "iopub.status.busy": "2024-07-17T17:32:26.350410Z",
     "iopub.status.idle": "2024-07-17T17:32:26.353826Z",
     "shell.execute_reply": "2024-07-17T17:32:26.353407Z",
     "shell.execute_reply.started": "2024-07-17T17:32:26.350805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "\n",
    "model.set_prompt(\"\"\"You are provided with the text extracted from a webpage, delimited by < for start and > for end. Your task is to extract the key phrases from the text that best characterize the webpage. You should extract at most 10 such phrases, but may extract less. Ensure the key phrases are relevant and provide a good summary of the content. Present the key phrases in JSON format, with each key phrase being an item in a list. Do not output anything but json of extracted keyphrases.\n",
    "\n",
    "Example webpage to extract from: <&>\n",
    "\n",
    "Your response should look like this:&\n",
    "\n",
    "The text from the webpage: <&>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cdb577c-f220-49f4-a115-c813c529a1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T19:35:47.620132Z",
     "iopub.status.busy": "2024-07-18T19:35:47.619436Z",
     "iopub.status.idle": "2024-07-18T19:35:49.810997Z",
     "shell.execute_reply": "2024-07-18T19:35:49.810295Z",
     "shell.execute_reply.started": "2024-07-18T19:35:47.620110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://378767f14fafe5d10f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://378767f14fafe5d10f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "def visualize(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Gradio function to extract and visualize key phrases from the given text.\n",
    "    Args:\n",
    "        text (str): The input text to extract key phrases from.\n",
    "    Returns:\n",
    "        str: The extracted key phrases formatted for display.\n",
    "    \"\"\"\n",
    "    formatted_phrases = inference.get_multiple_phrases(text)\n",
    "    output_text = \"Key phrases in the text are:\\n- \" + \"\\n- \".join(formatted_phrases)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Create the Gradio interface for key phrase extraction\n",
    "interface = gr.Interface(\n",
    "    fn=visualize,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text to extract the keywords from\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Key Phrase Extractor\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e143d0e6-3639-40b0-8b02-4227ba8d77d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:32:13.190179Z",
     "iopub.status.busy": "2024-07-18T17:32:13.189581Z",
     "iopub.status.idle": "2024-07-18T17:32:15.149333Z",
     "shell.execute_reply": "2024-07-18T17:32:15.148578Z",
     "shell.execute_reply.started": "2024-07-18T17:32:13.190155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://58e498d24bd5526765.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://58e498d24bd5526765.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def visualize2(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Gradio function to extract and visualize key phrases from the given text.\n",
    "    Args:\n",
    "        text (str): The input text to extract key phrases from.\n",
    "    Returns:\n",
    "        str: The extracted key phrases formatted for display.\n",
    "    \"\"\"\n",
    "    formatted_phrases = inference.get_search_phrases(text)\n",
    "    output_text = \"Search phrases in the text are:\\n- \" + \"\\n- \".join(formatted_phrases)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Create the Gradio interface for key phrase extraction\n",
    "interface = gr.Interface(\n",
    "    fn=visualize2,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text to extract the keywords from\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Key Phrase Extractor\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436e239b-26bf-44e2-b603-8e87124b8f73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
