{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete interaction trough GUI\n",
    "\n",
    "import llm_class\n",
    "import model_inference\n",
    "import prompts\n",
    "\n",
    "from constants import PHI_MODEL_NAME, EMBEDDING_MODEL_NAME\n",
    "from datetime import datetime\n",
    "from embedding import Embedder\n",
    "from model_eval import ModelEval\n",
    "from scraper import Scraper\n",
    "from searching import PageSearch\n",
    "from webpage import Webpage\n",
    "\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "\n",
    "model = llm_class.LanguageModel()\n",
    "inference = model_inference.ModelInferencing(model)\n",
    "\n",
    "\n",
    "# Function to update the interface components\n",
    "def select_webpage(webpage_url, page_num):\n",
    "    pages = Scraper.scrape_from_link(webpage_url, page_num)\n",
    "    new_pages = []\n",
    "\n",
    "    for i in range(len(pages)):\n",
    "        print(pages[i].link)\n",
    "        try:\n",
    "            text = pages[i].get_text()\n",
    "            phrases = inference.get_multiple_phrases(text)\n",
    "            emb_phrases = Embedder().get_embedding(phrases)  # Use instance method\n",
    "            pages[i].set_embedding(emb_phrases)\n",
    "            print(phrases)\n",
    "        except Exception as e:\n",
    "            print(f\"Page skipped due to error: {e}\")\n",
    "            continue\n",
    "        new_pages.append(pages[i])\n",
    "    \n",
    "    page_collection = PageSearch(new_pages)\n",
    "    \n",
    "    return (\n",
    "        gr.update(visible=False),\n",
    "        gr.update(visible=False),\n",
    "        gr.update(interactive=False),\n",
    "        gr.update(visible=True),\n",
    "        gr.update(visible=True),\n",
    "        page_collection\n",
    "    )\n",
    "\n",
    "def query_webpage(query, page_collection):\n",
    "    results = page_collection.search_pages(query, inference)\n",
    "    results.reverse()\n",
    "    links = []\n",
    "    scores = []\n",
    "    for item in results:\n",
    "        links.append(item['page'].link)\n",
    "        scores.append(item['relevance'])\n",
    "    \n",
    "    df = pd.DataFrame.from_dict({'links': links, 'scores': scores})\n",
    "    return df\n",
    "\n",
    "# Initial setup of the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    # Initial state\n",
    "    text = gr.Textbox(label=\"Webpage url\", interactive=True, visible=True)\n",
    "    page_num = gr.Slider(\n",
    "        label=\"Number of webpages to extract\",\n",
    "        value=1,\n",
    "        interactive=True,\n",
    "        minimum=1,\n",
    "        maximum=100,\n",
    "        step=1\n",
    "    )\n",
    "    button = gr.Button(\"Scrape the website\", visible=True)\n",
    "\n",
    "    text2 = gr.Textbox(label=\"Search box\", interactive=True, visible=False)\n",
    "    button2 = gr.Button(\"Search pages\", visible=False)\n",
    "    result_df = gr.Dataframe(\n",
    "        row_count=(20, \"fixed\"),\n",
    "        col_count=(2, \"fixed\"),\n",
    "        label=\"Most relevant pages\",\n",
    "        headers=['links', 'scores']\n",
    "    )\n",
    "    \n",
    "    # State to keep track of webpages\n",
    "    page_collection = gr.State(None)\n",
    "\n",
    "    # Click event to update components\n",
    "    button.click(\n",
    "        fn=select_webpage,\n",
    "        inputs=[text, page_num],\n",
    "        outputs=[page_num, button, text, text2, button2, page_collection]\n",
    "    )\n",
    "    \n",
    "    button2.click(\n",
    "        fn=query_webpage,\n",
    "        inputs=[text2, page_collection],\n",
    "        outputs=[result_df]\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b1d77-c135-48c2-b208-20b2923af38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T19:35:03.044365Z",
     "iopub.status.busy": "2024-07-18T19:35:03.043788Z",
     "iopub.status.idle": "2024-07-18T19:35:43.367000Z",
     "shell.execute_reply": "2024-07-18T19:35:43.366102Z",
     "shell.execute_reply.started": "2024-07-18T19:35:03.044331Z"
    }
   },
   "outputs": [],
   "source": [
    "# Init\n",
    "\n",
    "import keyphrase_dataset\n",
    "import llm_class\n",
    "import model_inference\n",
    "import output_parser\n",
    "import phrase_extraction_evaluation\n",
    "import prompts\n",
    "\n",
    "from datetime import datetime\n",
    "from constants import PHI_MODEL_NAME, EMBEDDING_MODEL_NAME\n",
    "from model_eval import ModelEval\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "model = llm_class.LanguageModel()\n",
    "keyphrase_set = keyphrase_dataset.KeyphraseDataset()\n",
    "inference = model_inference.ModelInferencing(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751c640-c08b-4ea9-baa3-48c7c08503a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T15:40:29.747622Z",
     "iopub.status.busy": "2024-07-18T15:40:29.747353Z",
     "iopub.status.idle": "2024-07-18T15:40:31.225032Z",
     "shell.execute_reply": "2024-07-18T15:40:31.224473Z",
     "shell.execute_reply.started": "2024-07-18T15:40:29.747602Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def gradio_func(text_prompt: str, samples: int, experiment_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Gradio function to run multiple samples and evaluate them.\n",
    "    Args:\n",
    "        text_prompt (str): The text prompt for generating key phrases.\n",
    "        samples (int): The number of samples to test.\n",
    "        experiment_name (str): The name of the experiment.\n",
    "    Returns:\n",
    "        str: The average metrics from the evaluation.\n",
    "    \"\"\"\n",
    "    prompts.multiple_keyphrases_prompt = text_prompt\n",
    "    tests = keyphrase_set.get_samples(samples)\n",
    "    results = ModelEval.multiple_samples(inference, tests, save_file=experiment_name, print_counts=True)\n",
    "\n",
    "    return (\n",
    "        f\"Avg cosine: {results['cosine']} | \"\n",
    "        f\"Avg labels matched: {results['matchings']} | \"\n",
    "        f\"Avg redundancy: {results['redundancy']} | \"\n",
    "        f\"Avg groundness: {results['groundness']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Create the Gradio interface for prompt testing\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_func,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text Prompt\"),\n",
    "        gr.Slider(minimum=1, maximum=500, step=1, label=\"Number of tests\"),\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your experiment name here...\", label=\"Experiment name\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Prompt Testing Interface\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97a6de-6100-497a-87f3-a81e7a806775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T18:06:32.305198Z",
     "iopub.status.busy": "2024-07-17T18:06:32.303979Z",
     "iopub.status.idle": "2024-07-17T18:06:35.632980Z",
     "shell.execute_reply": "2024-07-17T18:06:35.632506Z",
     "shell.execute_reply.started": "2024-07-17T18:06:32.305149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "\n",
    "sample=keyphrase_set.train_set[1]\n",
    "\n",
    "#print(model.prompt_text)\n",
    "\n",
    "print(sample['text'])\n",
    "print(\"\\n\")\n",
    "print(sample['label'])\n",
    "print(\"\\n\")\n",
    "print(get_metrics(sample['text'],sample['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76463564-cde9-4896-a481-06e71c66cf7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T17:32:26.350827Z",
     "iopub.status.busy": "2024-07-17T17:32:26.350410Z",
     "iopub.status.idle": "2024-07-17T17:32:26.353826Z",
     "shell.execute_reply": "2024-07-17T17:32:26.353407Z",
     "shell.execute_reply.started": "2024-07-17T17:32:26.350805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "\n",
    "model.set_prompt(\"\"\"You are provided with the text extracted from a webpage, delimited by < for start and > for end. Your task is to extract the key phrases from the text that best characterize the webpage. You should extract at most 10 such phrases, but may extract less. Ensure the key phrases are relevant and provide a good summary of the content. Present the key phrases in JSON format, with each key phrase being an item in a list. Do not output anything but json of extracted keyphrases.\n",
    "\n",
    "Example webpage to extract from: <&>\n",
    "\n",
    "Your response should look like this:&\n",
    "\n",
    "The text from the webpage: <&>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb577c-f220-49f4-a115-c813c529a1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T19:35:47.620132Z",
     "iopub.status.busy": "2024-07-18T19:35:47.619436Z",
     "iopub.status.idle": "2024-07-18T19:35:49.810997Z",
     "shell.execute_reply": "2024-07-18T19:35:49.810295Z",
     "shell.execute_reply.started": "2024-07-18T19:35:47.620110Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Gradio function to extract and visualize key phrases from the given text.\n",
    "    Args:\n",
    "        text (str): The input text to extract key phrases from.\n",
    "    Returns:\n",
    "        str: The extracted key phrases formatted for display.\n",
    "    \"\"\"\n",
    "    formatted_phrases = inference.get_multiple_phrases(text)\n",
    "    output_text = \"Key phrases in the text are:\\n- \" + \"\\n- \".join(formatted_phrases)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Create the Gradio interface for key phrase extraction\n",
    "interface = gr.Interface(\n",
    "    fn=visualize,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text to extract the keywords from\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Key Phrase Extractor\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143d0e6-3639-40b0-8b02-4227ba8d77d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T17:32:13.190179Z",
     "iopub.status.busy": "2024-07-18T17:32:13.189581Z",
     "iopub.status.idle": "2024-07-18T17:32:15.149333Z",
     "shell.execute_reply": "2024-07-18T17:32:15.148578Z",
     "shell.execute_reply.started": "2024-07-18T17:32:13.190155Z"
    }
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def visualize2(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Gradio function to extract and visualize key phrases from the given text.\n",
    "    Args:\n",
    "        text (str): The input text to extract key phrases from.\n",
    "    Returns:\n",
    "        str: The extracted key phrases formatted for display.\n",
    "    \"\"\"\n",
    "    formatted_phrases = inference.get_search_phrases(text)\n",
    "    output_text = \"Search phrases in the text are:\\n- \" + \"\\n- \".join(formatted_phrases)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "\n",
    "# Create the Gradio interface for search phrase extraction\n",
    "interface = gr.Interface(\n",
    "    fn=visualize2,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text to extract the keywords from\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Key Phrase Extractor\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214445b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
