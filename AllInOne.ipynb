{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "933b1d77-c135-48c2-b208-20b2923af38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:46:20.071097Z",
     "iopub.status.busy": "2024-07-18T12:46:20.070420Z",
     "iopub.status.idle": "2024-07-18T12:46:22.953569Z",
     "shell.execute_reply": "2024-07-18T12:46:22.953181Z",
     "shell.execute_reply.started": "2024-07-18T12:46:20.071075Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c171dc851dd0434b98d7113b111aecbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import llm_class\n",
    "import output_parser\n",
    "import phrase_extraction_evaluation\n",
    "from model_eval import Model_eval\n",
    "import keyphrase_dataset\n",
    "import model_inference\n",
    "\n",
    "model = llm_class.LanguageModel()\n",
    "keyphrase_set = keyphrase_dataset.KeyphraseDataset()\n",
    "inference = model_inference.ModelInferencing(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4751c640-c08b-4ea9-baa3-48c7c08503a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import prompts\n",
    "\n",
    "def gradio_func(text_prompt, samples,experiment_name):\n",
    "    prompts.multiple_keyphrases_prompt=text_prompt\n",
    "    tests = keyphrase_set.get_samples(samples)\n",
    "    results = Model_eval.multiple_samples(inference, tests, save_file=\"default\", print_counts=True)\n",
    "    \n",
    "    return f\"Avg cosine: {results['cosine']} | Avg labels matched: {results['matchings']} | Avg redundancy: {results['redundancy']} | Avg groundness: {results['groundness']}\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_func,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text Prompt\"),\n",
    "        gr.Slider(minimum=1, maximum=500, step=1, label=\"Number of tests\"),\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Experiment name\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Prompt testing interface\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76463564-cde9-4896-a481-06e71c66cf7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T17:32:26.350827Z",
     "iopub.status.busy": "2024-07-17T17:32:26.350410Z",
     "iopub.status.idle": "2024-07-17T17:32:26.353826Z",
     "shell.execute_reply": "2024-07-17T17:32:26.353407Z",
     "shell.execute_reply.started": "2024-07-17T17:32:26.350805Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "\n",
    "model.set_prompt(\"\"\"You are provided with the text extracted from a webpage, delimited by < for start and > for end. Your task is to extract the key phrases from the text that best characterize the webpage. You should extract at most 10 such phrases, but may extract less. Ensure the key phrases are relevant and provide a good summary of the content. Present the key phrases in JSON format, with each key phrase being an item in a list. Do not output anything but json of extracted keyphrases.\n",
    "\n",
    "Example webpage to extract from: <&>\n",
    "\n",
    "Your response should look like this:&\n",
    "\n",
    "The text from the webpage: <&>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cdb577c-f220-49f4-a115-c813c529a1b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T12:47:50.257930Z",
     "iopub.status.busy": "2024-07-18T12:47:50.257687Z",
     "iopub.status.idle": "2024-07-18T12:47:51.676524Z",
     "shell.execute_reply": "2024-07-18T12:47:51.675986Z",
     "shell.execute_reply.started": "2024-07-18T12:47:50.257912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://4980806db5e7064156.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4980806db5e7064156.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating prompts with gradio\n",
    "\n",
    "import gradio as gr\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def visualize(text):\n",
    "    formated_phrases=inference.get_multiple_phrases(text)\n",
    "    output_text=\"Key phrases in the text are:\\n- \" + \"\\n- \".join(formated_phrases)\n",
    "    \n",
    "    return output_text\n",
    "\n",
    "# Create the Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=visualize,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter your text prompt here...\", label=\"Text to extract the keywords from\"),\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"Key phrase extractor\",\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97a6de-6100-497a-87f3-a81e7a806775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T18:06:32.305198Z",
     "iopub.status.busy": "2024-07-17T18:06:32.303979Z",
     "iopub.status.idle": "2024-07-17T18:06:35.632980Z",
     "shell.execute_reply": "2024-07-17T18:06:35.632506Z",
     "shell.execute_reply.started": "2024-07-17T18:06:32.305149Z"
    }
   },
   "outputs": [],
   "source": [
    "# Debug\n",
    "\n",
    "sample=keyphrase_set.train_set[1]\n",
    "\n",
    "#print(model.prompt_text)\n",
    "\n",
    "print(sample['text'])\n",
    "print(\"\\n\")\n",
    "print(sample['label'])\n",
    "print(\"\\n\")\n",
    "print(get_metrics(sample['text'],sample['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e143d0e6-3639-40b0-8b02-4227ba8d77d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
